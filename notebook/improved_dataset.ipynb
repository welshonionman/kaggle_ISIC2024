{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_save_path = \"/kaggle/input/isic_archive_malignant\"\n",
    "archive_meta_path = archive_save_path + \"/metadata.csv\"\n",
    "\n",
    "improved_save_path = \"/kaggle/input/improved_dataset/\"\n",
    "improved_meta_path = improved_save_path + \"/metadata.csv\"\n",
    "\n",
    "save_dir = Path(f\"{improved_save_path}/train_image\")\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "orig_dataset_path = \"/kaggle/input/isic-2024-challenge/train-image/image\"\n",
    "orig_meta_path = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/isic_archive_malignant_resized/metadata.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def center_crop(img: np.ndarray):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if width > height:\n",
    "        diff = width - height\n",
    "        img = img[:, diff // 2 : -diff // 2, :]\n",
    "    elif height > width:\n",
    "        diff = height - width\n",
    "        img = img[diff // 2 : -diff // 2, :, :]\n",
    "    else:\n",
    "        pass\n",
    "    return img\n",
    "\n",
    "\n",
    "def save_resized(img_path_list, save_dir, size):\n",
    "    for img_path in img_path_list:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = center_crop(img)\n",
    "        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_LANCZOS4)\n",
    "        save_path = f\"{save_dir}/{img_path.name}\"\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "\n",
    "img_path_list = list(Path(archive_save_path).glob(\"*.jpg\"))\n",
    "\n",
    "\n",
    "save_resized(img_path_list, save_dir, 384)\n",
    "\n",
    "for img_p in Path(orig_dataset_path).glob(\"*\"):\n",
    "    shutil.copy(img_p, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5_dataset(img_paths_list, hdf5_path):\n",
    "    f = h5py.File(hdf5_path, \"w\")\n",
    "\n",
    "    for img_p in tqdm(img_paths_list):\n",
    "        ext = os.path.splitext(img_p)[1][1:]\n",
    "        if ext != \"jpg\":\n",
    "            print(\"%s does not have a supported extension. Skipping!!\" % (img_p))\n",
    "            continue\n",
    "        if ext == \"JPG\" or ext == \"jpg\":\n",
    "            fin = open(img_p, \"rb\")\n",
    "            binary_data = fin.read()\n",
    "            binary_data_np = np.asarray(binary_data)\n",
    "            fin.close()\n",
    "\n",
    "        fname = os.path.splitext(os.path.basename(img_p))[0]\n",
    "        f.create_dataset(fname, data=binary_data_np)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_list = list(Path(f\"{improved_save_path}/train_image\").glob(\"*.jpg\"))\n",
    "hdf_path = f\"{improved_save_path}/train_image.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408259/408259 [00:27<00:00, 14993.97it/s]\n"
     ]
    }
   ],
   "source": [
    "create_hdf5_dataset(img_paths_list, hdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1926297/492266722.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  orig_meta = pd.read_csv(orig_meta_path)\n"
     ]
    }
   ],
   "source": [
    "archive_meta = pd.read_csv(archive_meta_path)\n",
    "orig_meta = pd.read_csv(orig_meta_path)\n",
    "archive_meta[\"patient_id\"] = archive_meta[\"patient_id\"].fillna(\n",
    "    archive_meta.index.to_series()\n",
    ")\n",
    "archive_meta[\"source\"] = \"archive\"\n",
    "orig_meta[\"source\"] = \"orig\"\n",
    "pd.concat([orig_meta, archive_meta], axis=0).to_csv(improved_meta_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
